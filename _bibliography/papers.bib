@inproceedings{kargaran-etal-2024-masklid,
	title        = {MaskLID: Code-Switching Language Identification through Iterative Masking},
	author       = {Kargaran, Amir Hossein and Yvon, Fran{\c{c}}ois and Sch{\"u}tze, Hinrich},
	year         = 2024,
	booktitle    = {Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
	publisher    = {Association for Computational Linguistics},
	address      = {Bangkok, Thailand},
  abbr         = {ACL 2024},
  abstract     = {We present MaskLID, a simple, yet effective, code-switching (CS) language identification (LID) method. MaskLID does not require any training and is designed to complement current high-performance sentence-level LIDs. Sentence-level LIDs are classifiers trained on monolingual texts to provide single labels, typically using a softmax layer to turn scores into probabilities. However, in cases where a sentence is composed in both L1 and L2 languages, the LID classifier often only returns the dominant label L1. To address this limitation, MaskLID employs a strategy to mask text features associated with L1, allowing the LID to classify the text as L2 in the next round. This method uses the LID itself to identify the features that require masking and does not rely on any external resource. In this work, we explore the use of MaskLID for two open-source LIDs (GlotLID and OpenLID), that are both based on the FastText architecture. Code and demo are available at https://github.com/cisnlp/MaskLID},
  selected     = true,
  arxiv        = {2406.06263},
  pdf          = {paper-masklid-acl-2024.pdf},
  code         = {https://github.com/cisnlp/MaskLID},
  demo         = {https://huggingface.co/spaces/cis-lmu/MaskLID},
}

@inproceedings{kargaran-2023-glotlid,
	title        = {{GlotLID}: Language Identification for Low-Resource Languages},
	author       = {Kargaran, Amir Hossein and Imani, Ayyoob and Yvon, Fran{\c{c}}ois and Sch{\"u}tze, Hinrich},
	year         = 2023,
	booktitle    = {The 2023 Conference on Empirical Methods in Natural Language Processing},
	acl          = {https://openreview.net/forum?id=dl4e3EBz5j},
  selected     = true,
  abbr         = {EMNLP 2023},
  abstract     = {Several recent papers have published good solutions for language identification (LID) for about 300 high-resource and medium-resource languages. However, there is no LID available that (i) covers a wide range of low-resource languages, (ii) is rigorously evaluated and reliable and (iii) efficient and easy to use. Here, we publish GlotLID-M, an LID model that satisfies the desiderata of wide coverage, reliability and efficiency. It identifies 1665 languages, a large increase in coverage compared to prior work. In our experiments, GlotLID-M outperforms four baselines (CLD3, FT176, OpenLID and NLLB) when balancing F1 and false positive rate (FPR). We analyze the unique challenges that low-resource LID poses: incorrect corpus metadata, leakage from high-resource languages, difficulty separating closely related languages, handling of macrolanguage vs varieties and in general noisy data. We hope that integrating GlotLID-M into dataset creation pipelines will improve quality and enhance accessibility of NLP technology for low-resource languages and cultures. GlotLID-M model, code, and list of data sources are available: https://github.com/cisnlp/GlotLID.},
  arxiv        = {2310.16248},
  pdf          = {paper-glotlid-emnlp-2023.pdf},
  slides       = {poster-glotlid-emnlp-2023.pdf},
  code         = {https://github.com/cisnlp/GlotLID},
  demo         = {https://huggingface.co/spaces/cis-lmu/glotlid-space},
}

@article{kargaran-2024-glotscript,
	title        = {GlotScript: A Resource and Tool for Low Resource Writing System Identification},
	author       = {Kargaran, Amir Hossein and Yvon, Fran{\c{c}}ois and Sch{\"u}tze, Hinrich},
	year         = 2024,
	journal      = {The 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation},
  selected     = false,
  oral         = {},
  abbr         = {LREC 2024},
  abstract     = {We present GlotScript, an open resource and tool for low resource writing system identification. GlotScript-R is a resource that provides the attested writing systems for more than 7,000 languages. It is compiled by aggregating information from existing writing system resources. GlotScript-T is a writing system identification tool that covers all 161 Unicode 15.0 scripts. For an input text, it returns its script distribution where scripts are identified by ISO 15924 codes. We also present two use cases for GlotScript. First, we demonstrate that GlotScript supports cleaning multilingual corpora such as mC4 and OSCAR. Second, we analyze the tokenization of a number of language models such as GPT-4 using GlotScript and provide insights on the coverage of low resource scripts and languages by each language model. We hope that GlotScript will become a useful resource for work on low resource languages in the NLP community. GlotScript-R and GlotScript-T are available at https://github.com/cisnlp/GlotScript.},
  code         = {https://github.com/cisnlp/GlotScript},
  slides       = {slides-glotscript-lrec-2024.pdf},
  arxiv        = {2309.13320},
}

@inproceedings{nikeghbal-2024-girtmodel,
  title        = {GIRT-Model: Automated Generation of Issue Report Templates},
  booktitle    = {21st IEEE/ACM International Conference on Mining Software Repositories (MSR)},
  author       = {Nikeghbal, Nafiseh and Kargaran, Amir Hossein and Heydarnoori, Abbas},
  month        = {April},
  year         = 2024,
  publisher    = {IEEE/ACM},
  address      = {Lisbon, Portugal},
  acm          = {https://doi.org/10.1145/3643991.3644906},
  arxiv        = {2402.02632},
  selected     = false,
  abbr         = {MSR 2024},
  abstract     = {Platforms such as GitHub and GitLab introduce Issue Report Templates (IRTs) to enable more effective issue management and better alignment with developer expectations. However, these templates are not widely adopted in most repositories, and there is currently no tool available to aid developers in generating them. In this work, we introduce GIRT-Model, an assistant language model that automatically generates IRTs based on the developer's instructions regarding the structure and necessary fields. We create GIRT-Instruct, a dataset comprising pairs of instructions and IRTs, with the IRTs sourced from GitHub repositories. We use GIRT-Instruct to instruction-tune a T5-base model to create the GIRT-Model. In our experiments, GIRT-Model outperforms general language models (T5 and Flan-T5 with different parameter sizes) in IRT generation by achieving significantly higher scores in ROUGE, BLEU, METEOR, and human evaluation. Additionally, we analyze the effectiveness of GIRT-Model in a user study in which participants wrote short IRTs with GIRT-Model. Our results show that the participants find GIRT-Model useful in the automated generation of templates. We hope that through the use of GIRT-Model, we can encourage more developers to adopt IRTs in their repositories. We publicly release our code, dataset, and model at https://github.com/ISE-Research/girt-model.},
  code         = {https://github.com/ISE-Research/girt-model},
}

@inproceedings{imanigooghari-2023-glot,
  title        = {Glot500: Scaling Multilingual Corpora and Language Models to 500 Languages},
  author       = {ImaniGooghari, Ayyoob and Lin, Peiqin and Kargaran, Amir Hossein and Severini, Silvia and Sabet, Masoud Jalili and Kassner, Nora and Ma, Chunlan and Schmid, Helmut and Martins, André and Yvon, François and Sch{\"u}tze, Hinrich},
  year         = 2023,
  booktitle    = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  publisher    = {Association for Computational Linguistics},
  abbr         = {ACL 2023},
  acl          = {https://aclanthology.org/2023.acl-long.61},
  area_chair_award = {https://2023.aclweb.org/program/best_papers/},
  pdf          = {paper-glot500-acl-2023.pdf},
  code         = {https://github.com/cisnlp/Glot500},
  arxiv        = {2305.12182},
  selected     = false,
  oral         = {},
  abstract     = {The NLP community has mainly focused on scaling Large Language Models (LLMs) vertically, i.e., making them better for about 100 languages. We instead scale LLMs horizontally: we create, through continued pretraining, Glot500-m, an LLM that covers 511 predominantly low-resource languages. An important part of this effort is to collect and clean Glot500-c, a corpus that covers these 511 languages and allows us to train Glot500-m. We evaluate Glot500-m on five diverse tasks across these languages. We observe large improvements for both high-resource and low-resource languages compared to an XLM-R baseline. Our analysis shows that no single factor explains the quality of multilingual LLM representations. Rather, a combination of factors determines quality including corpus size, script, "help" from related languages and the total capacity of the model. Our work addresses an important goal of NLP research: we should not limit NLP to a small fraction of the world's languages and instead strive to support as many languages as possible to bring the benefits of NLP technology to all languages and cultures. Code, data and models are available at https://github.com/cisnlp/Glot500.}
}

@inproceedings{nikeghbal-2023-girtdata,
  title        = {GIRT-Data: Sampling GitHub Issue Report Templates},
  author       = {Nikeghbal, Nafiseh and Kargaran, Amir Hossein and Heydarnoori, Abbas and Sch{\"u}tze, Hinrich},
  year         = 2023,
  booktitle    = {IEEE/ACM 20th International Conference on Mining Software Repositories (MSR)},
  abbr         = {MSR 2023},
  code         = {https://github.com/kargaranamir/girt-data},
  ieee         = {https://ieeexplore.ieee.org/document/10174016},
  pdf          = {https://arxiv.org/pdf/2303.09236.pdf},
  arxiv        = {2303.09236},
  selected     = false,
  abstract     = {GitHub's issue reports provide developers with valuable information that is essential to the evolution of a software development project. Contributors can use these reports to perform software engineering tasks like submitting bugs, requesting features, and collaborating on ideas. In the initial versions of issue reports, there was no standard way of using them. As a result, the quality of issue reports varied widely. To improve the quality of issue reports, GitHub introduced issue report templates (IRTs), which pre-fill issue descriptions when a new issue is opened. An IRT usually contains greeting contributors, describing project guidelines, and collecting relevant information. However, despite of effectiveness of this feature which was introduced in 2016, only nearly 5% of GitHub repositories (with more than 10 stars) utilize it. There are currently few articles on IRTs, and the available ones only consider a small number of repositories. In this work, we introduce GIRT-Data, the first and largest dataset of IRTs in both YAML and Markdown format. This dataset and its corresponding open-source crawler tool are intended to support research in this area and to encourage more developers to use IRTs in their repositories. The stable version of the dataset contains 1,084,300 repositories and 50,032 of them support IRTs. The stable version of the dataset and crawler is available here: https://github.com/kargaranamir/girt-data}
}

@article{kargaran-2023-menucraft,
  title        = {MenuCraft: Interactive Menu System Design with Large Language Models},
  author       = {Kargaran, Amir Hossein and Nikeghbal, Nafiseh and Heydarnoori, Abbas and Sch{\"u}tze, Hinrich},
  year         = 2023,
  journal      = {arXiv preprint arXiv:2303.04496},
  abbr         = {arXiv 2023},
  arxiv        = {2303.04496},
  demo      = {https://kargaranamir.github.io/MenuCraft},
  pdf          = {https://arxiv.org/pdf/2303.04496.pdf},
  selected     = false,
  abstract     = {Menu system design is a challenging task involving many design options and various human factors. For example, one crucial factor that designers need to consider is the semantic and systematic relation of menu commands. However, capturing these relations can be challenging due to limited available resources. With the advancement of neural language models, large language models can utilize their vast pre-existing knowledge in designing and refining menu systems. In this paper, we propose MenuCraft, an AI-assisted designer for menu design that enables collaboration between the designer and a dialogue system to design menus. MenuCraft offers an interactive language-based menu design tool that simplifies the menu design process and enables easy customization of design options. MenuCraft supports a variety of interactions through dialog that allows performing few-shot learning.}
}

@inproceedings{kargaran-2022-hengam,
  title        = {Hengam: An Adversarially Trained Transformer for Persian Temporal Tagging},
  author       = {Mirzababaei, Sajad  and Kargaran, Amir Hossein  and Schütze, Hinrich  and Asgari, Ehsaneddin},
  year         = 2022,
  booktitle    = {Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  publisher    = {Association for Computational Linguistics},
  address      = {Online only},
  pages        = {1013--1024},
  abbr         = {AACL 2022},
  pdf          = {https://aclanthology.org/2022.aacl-main.74.pdf},
  code         = {https://github.com/kargaranamir/hengam},
  acl          = {https://aclanthology.org/2022.aacl-main.74},
  video        = {https://www.youtube.com/watch?v=AaGBK1YRPZ4},
  code         = {https://github.com/kargaranamir/hengam},
  selected     = false,
  abstract     = {Many NLP main tasks benefit from an accurate understanding of temporal expressions, e.g., text summarization, question answering, and information retrieval. This paper introduces Hengam, an adversarially trained transformer for Persian temporal tagging outperforming state-of-the-art approaches on a diverse and manually created dataset. We create Hengam in the following concrete steps: (1) we develop HengamTagger, an extensible rule-based tool that can extract temporal expressions from a set of diverse language-specific patterns for any language of interest. (2) We apply HengamTagger to annotate temporal tags in a large and diverse Persian text collection (covering both formal and informal contexts) to be used as weakly labeled data. (3) We introduce an adversarially trained transformer model on HengamCorpus that can generalize over the HengamTagger’s rules. We create HengamGold, the first high-quality gold standard for Persian temporal tagging. Our trained adversarial HengamTransformer not only achieves the best performance in terms of the F1-score (a type F1-Score of 95.42 and a partial F1-Score of 91.60) but also successfully deals with language ambiguities and incorrect spellings. Our code, data, and models are publicly available at https://github.com/kargaranamir/Hengam.}
}
@inproceedings{kargaran-2021-wideadgraph,
  title        = {Wide-AdGraph: Detecting Ad Trackers with a Wide Dependency Chain Graph},
  author       = {Kargaran, Amir Hossein and Akhondzadeh, Mohammad Sadegh and Heidarpour, Mohammad Reza and Manshaei, Mohammad Hossein and Salamatian, Kave and Nejad Sattary, Masoud},
  year         = 2021,
  booktitle    = {13th ACM Web Science Conference},
  publisher    = {Association for Computing Machinery},
  address      = {Virtual Event, United Kingdom},
  pages        = {253--261},
  doi          = {10.1145/3447535.3462549},
  abbr         = {WEBSCI 2021},
  pdf_v2       = {paper-wideadgraph-websci-2021.pdf},
  pdf_v1       = {paper-detecting-arxiv-2020.pdf},
  acm          = {https://dl.acm.org/doi/abs/10.1145/3447535.3462549},
  video        = {https://www.youtube.com/watch?v=PpFpfEMVze0},
  code         = {https://github.com/kargaranamir/Wide-AdGraph},
  arxiv        = {2004.14826},
  selected     = false,
  best_student_paper = {https://www.acm.org/conferences/best-paper-awards},
  abstract     = {Websites use third-party ads and tracking services to deliver targeted ads and collect information about users that visit them. These services put users’ privacy at risk, and that is why users’ demand for blocking these services is growing. Most of the blocking solutions rely on crowd-sourced filter lists manually maintained by a large community of users. In this work, we seek to simplify the update of these filter lists by combining different websites through a large-scale graph connecting all resource requests made over a large set of sites. The features of this graph are extracted and used to train a machine learning algorithm with the aim of detecting ads and tracking resources. As our approach combines different information sources, it is more robust toward evasion techniques that use obfuscation or changing the usage patterns. We evaluate our work over the Alexa top-10K websites and find its accuracy to be 96.1% biased and 90.9% unbiased with high precision and recall. It can also block new ads and tracking services, which would necessitate being blocked by further crowd-sourced existing filter lists. Moreover, the approach followed in this paper sheds light on the ecosystem of third-party tracking and advertising.}
}

@article{kargaran-2021-alramsimilarity,
  title        = {Analytical Derivation and Comparison of Alarm Similarity Measures},
  author       = {Kargaran, Amir Hossein and Neshastegaran, Amir and Izadi, Iman and Yazdian, Ehsan},
  year         = 2021,
  journal      = {IFAC-PapersOnLine},
  publisher    = {Elsevier},
  volume       = 54,
  number       = 3,
  pages        = {360--365},
  doi          = {10.1016/j.ifacol.2021.08.268},
  abbr         = {ADCHEM 2021},
  website      = {https://www.sciencedirect.com/science/article/pii/S2405896321010417},
  pdf_v2       = {https://arxiv.org/pdf/2003.10600.pdf},
  pdf_v1       = {paper-alarm-arxiv-2020.pdf},
  arxiv        = {2003.10600},
  video        = {https://www.youtube.com/watch?v=8_EB3OgtE2s},
  code         = {https://github.com/kargaranamir/Alarm-Similarity},
  selected     = false,
  abstract     = {An industrial process includes many devices, variables, and sub-processes that are physically or electronically interconnected. These interconnections imply some level of correlation between different process variables. Since most of the alarms in a process plant are defined on process variables, alarms are also correlated. However, this can be a nuisance to operators, for one fault might trigger a, sometimes large, number of alarms. So, it is essential to find and correct correlated alarms. In this paper, we study different methods and techniques proposed to measure correlation or similarity between alarms. The similarity indices are first analytically calculated and then studied and compared. The results are also validated using Monte-Carlo simulation.}
}
